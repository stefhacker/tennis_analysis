{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import models, transforms \n",
    "import json\n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keypoints(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.49, 0.45, 0.4], std=[0.23, 0.225,0.224])\n",
    "\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image at {self.img_dir}/{item['id']}.png could not be loaded.\")\n",
    "\n",
    "       \n",
    "        h, w = img.shape[:2] #height and width of image\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224 / w #adjust x coordinates after transformation to 224x224\n",
    "        kps[1::2] *= 224 / h #adjust y coordinates\n",
    "\n",
    "        return img, kps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Keypoints(\"tennis_court_det_dataset/data/images\", \"tennis_court_det_dataset/data/data_train.json\")\n",
    "val_dataset = Keypoints(\"tennis_court_det_dataset/data/images\", \"tennis_court_det_dataset/data/data_val.json\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "#replaces last layer 14 is number of keypoints (x,y coordinate) on the tennis court\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14*2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoch 0, iter 0, loss 14541.5947265625\n",
      "Epcoch 0, iter 10, loss 14266.8154296875\n",
      "Epcoch 0, iter 20, loss 14293.3134765625\n",
      "Epcoch 0, iter 30, loss 14820.3701171875\n",
      "Epcoch 0, iter 40, loss 13329.806640625\n",
      "Epcoch 0, iter 50, loss 12874.27734375\n",
      "Epcoch 0, iter 60, loss 12379.6474609375\n",
      "Epcoch 0, iter 70, loss 11667.591796875\n",
      "Epcoch 0, iter 80, loss 11633.2451171875\n",
      "Epcoch 0, iter 90, loss 11044.826171875\n",
      "Epcoch 0, iter 100, loss 11315.2216796875\n",
      "Epcoch 0, iter 110, loss 11036.2470703125\n",
      "Epcoch 0, iter 120, loss 10634.67578125\n",
      "Epcoch 0, iter 130, loss 10159.4267578125\n",
      "Epcoch 0, iter 140, loss 9671.05859375\n",
      "Epcoch 0, iter 150, loss 9237.056640625\n",
      "Epcoch 0, iter 160, loss 8965.0068359375\n",
      "Epcoch 0, iter 170, loss 8608.181640625\n",
      "Epcoch 0, iter 180, loss 8447.568359375\n",
      "Epcoch 0, iter 190, loss 7912.4287109375\n",
      "Epcoch 0, iter 200, loss 7990.23876953125\n",
      "Epcoch 0, iter 210, loss 8317.884765625\n",
      "Epcoch 0, iter 220, loss 7191.78515625\n",
      "Epcoch 0, iter 230, loss 6998.5693359375\n",
      "Epcoch 0, iter 240, loss 6724.4755859375\n",
      "Epcoch 0, iter 250, loss 6399.49365234375\n",
      "Epcoch 0, iter 260, loss 6532.33154296875\n",
      "Epcoch 0, iter 270, loss 5988.08154296875\n",
      "Epcoch 0, iter 280, loss 5485.83642578125\n",
      "Epcoch 0, iter 290, loss 5389.171875\n",
      "Epcoch 0, iter 300, loss 4879.40625\n",
      "Epcoch 0, iter 310, loss 5119.876953125\n",
      "Epcoch 0, iter 320, loss 4973.6103515625\n",
      "Epcoch 0, iter 330, loss 4465.7734375\n",
      "Epcoch 0, iter 340, loss 4048.83349609375\n",
      "Epcoch 0, iter 350, loss 3912.7568359375\n",
      "Epcoch 0, iter 360, loss 4014.037109375\n",
      "Epcoch 0, iter 370, loss 3380.315673828125\n",
      "Epcoch 0, iter 380, loss 3787.74755859375\n",
      "Epcoch 0, iter 390, loss 3454.481689453125\n",
      "Epcoch 0, iter 400, loss 3185.716552734375\n",
      "Epcoch 0, iter 410, loss 3199.566650390625\n",
      "Epcoch 0, iter 420, loss 2952.024658203125\n",
      "Epcoch 0, iter 430, loss 2907.781982421875\n",
      "Epcoch 0, iter 440, loss 2845.30029296875\n",
      "Epcoch 0, iter 450, loss 2537.117919921875\n",
      "Epcoch 0, iter 460, loss 2636.283203125\n",
      "Epcoch 0, iter 470, loss 2331.895751953125\n",
      "Epcoch 0, iter 480, loss 2184.695068359375\n",
      "Epcoch 0, iter 490, loss 2063.779052734375\n",
      "Epcoch 0, iter 500, loss 1776.566162109375\n",
      "Epcoch 0, iter 510, loss 1682.37646484375\n",
      "Epcoch 0, iter 520, loss 1597.16943359375\n",
      "Epcoch 0, iter 530, loss 1621.22021484375\n",
      "Epcoch 0, iter 540, loss 1468.6219482421875\n",
      "Epcoch 0, iter 550, loss 1477.3023681640625\n",
      "Epcoch 0, iter 560, loss 1291.9481201171875\n",
      "Epcoch 0, iter 570, loss 1303.8250732421875\n",
      "Epcoch 0, iter 580, loss 1289.30029296875\n",
      "Epcoch 0, iter 590, loss 1239.04833984375\n",
      "Epcoch 0, iter 600, loss 1171.8916015625\n",
      "Epcoch 0, iter 610, loss 1035.186279296875\n",
      "Epcoch 0, iter 620, loss 859.0119018554688\n",
      "Epcoch 0, iter 630, loss 899.3486328125\n",
      "Epcoch 0, iter 640, loss 911.95556640625\n",
      "Epcoch 0, iter 650, loss 692.4014282226562\n",
      "Epcoch 0, iter 660, loss 685.0103759765625\n",
      "Epcoch 0, iter 670, loss 894.4317016601562\n",
      "Epcoch 0, iter 680, loss 779.3871459960938\n",
      "Epcoch 0, iter 690, loss 541.97802734375\n",
      "Epcoch 0, iter 700, loss 568.1815185546875\n",
      "Epcoch 0, iter 710, loss 525.7432861328125\n",
      "Epcoch 0, iter 720, loss 488.46734619140625\n",
      "Epcoch 0, iter 730, loss 568.407958984375\n",
      "Epcoch 0, iter 740, loss 355.8462219238281\n",
      "Epcoch 0, iter 750, loss 393.7991943359375\n",
      "Epcoch 0, iter 760, loss 515.0387573242188\n",
      "Epcoch 0, iter 770, loss 476.7912902832031\n",
      "Epcoch 0, iter 780, loss 288.2427978515625\n",
      "Epcoch 0, iter 790, loss 376.85150146484375\n",
      "Epcoch 0, iter 800, loss 282.149169921875\n",
      "Epcoch 0, iter 810, loss 295.3402099609375\n",
      "Epcoch 0, iter 820, loss 327.7157287597656\n",
      "Epcoch 1, iter 0, loss 290.4325866699219\n",
      "Epcoch 1, iter 10, loss 310.7406005859375\n",
      "Epcoch 1, iter 20, loss 203.6038360595703\n",
      "Epcoch 1, iter 30, loss 165.1796417236328\n",
      "Epcoch 1, iter 40, loss 153.12484741210938\n",
      "Epcoch 1, iter 50, loss 143.29808044433594\n",
      "Epcoch 1, iter 60, loss 174.44839477539062\n",
      "Epcoch 1, iter 70, loss 177.45716857910156\n",
      "Epcoch 1, iter 80, loss 112.97249603271484\n",
      "Epcoch 1, iter 90, loss 152.86544799804688\n",
      "Epcoch 1, iter 100, loss 109.02268981933594\n",
      "Epcoch 1, iter 110, loss 110.08551025390625\n",
      "Epcoch 1, iter 120, loss 114.90457916259766\n",
      "Epcoch 1, iter 130, loss 78.7796859741211\n",
      "Epcoch 1, iter 140, loss 99.35179138183594\n",
      "Epcoch 1, iter 150, loss 86.13053894042969\n",
      "Epcoch 1, iter 160, loss 65.56309509277344\n",
      "Epcoch 1, iter 170, loss 97.76801300048828\n",
      "Epcoch 1, iter 180, loss 58.495628356933594\n",
      "Epcoch 1, iter 190, loss 68.60250854492188\n",
      "Epcoch 1, iter 200, loss 61.516456604003906\n",
      "Epcoch 1, iter 210, loss 65.88522338867188\n",
      "Epcoch 1, iter 220, loss 56.57197189331055\n",
      "Epcoch 1, iter 230, loss 54.73612594604492\n",
      "Epcoch 1, iter 240, loss 37.35356521606445\n",
      "Epcoch 1, iter 250, loss 76.5724105834961\n",
      "Epcoch 1, iter 260, loss 51.12423324584961\n",
      "Epcoch 1, iter 270, loss 65.93094635009766\n",
      "Epcoch 1, iter 280, loss 44.236080169677734\n",
      "Epcoch 1, iter 290, loss 158.6853790283203\n",
      "Epcoch 1, iter 300, loss 47.08262252807617\n",
      "Epcoch 1, iter 310, loss 83.80686950683594\n",
      "Epcoch 1, iter 320, loss 39.579620361328125\n",
      "Epcoch 1, iter 330, loss 33.004905700683594\n",
      "Epcoch 1, iter 340, loss 61.90027618408203\n",
      "Epcoch 1, iter 350, loss 61.13911819458008\n",
      "Epcoch 1, iter 360, loss 77.52720642089844\n",
      "Epcoch 1, iter 370, loss 37.09010314941406\n",
      "Epcoch 1, iter 380, loss 25.206165313720703\n",
      "Epcoch 1, iter 390, loss 50.90440368652344\n",
      "Epcoch 1, iter 400, loss 31.727083206176758\n",
      "Epcoch 1, iter 410, loss 88.91411590576172\n",
      "Epcoch 1, iter 420, loss 64.61797332763672\n",
      "Epcoch 1, iter 430, loss 43.451114654541016\n",
      "Epcoch 1, iter 440, loss 21.23114585876465\n",
      "Epcoch 1, iter 450, loss 37.306617736816406\n",
      "Epcoch 1, iter 460, loss 62.997528076171875\n",
      "Epcoch 1, iter 470, loss 28.018230438232422\n",
      "Epcoch 1, iter 480, loss 59.676395416259766\n",
      "Epcoch 1, iter 490, loss 65.18870544433594\n",
      "Epcoch 1, iter 500, loss 31.279556274414062\n",
      "Epcoch 1, iter 510, loss 30.170717239379883\n",
      "Epcoch 1, iter 520, loss 78.35709381103516\n",
      "Epcoch 1, iter 530, loss 28.07353401184082\n",
      "Epcoch 1, iter 540, loss 32.89402770996094\n",
      "Epcoch 1, iter 550, loss 91.6209487915039\n",
      "Epcoch 1, iter 560, loss 102.2836685180664\n",
      "Epcoch 1, iter 570, loss 41.49139404296875\n",
      "Epcoch 1, iter 580, loss 32.999732971191406\n",
      "Epcoch 1, iter 590, loss 123.74583435058594\n",
      "Epcoch 1, iter 600, loss 26.14083480834961\n",
      "Epcoch 1, iter 610, loss 45.668006896972656\n",
      "Epcoch 1, iter 620, loss 36.46074295043945\n",
      "Epcoch 1, iter 630, loss 61.526123046875\n",
      "Epcoch 1, iter 640, loss 59.28786087036133\n",
      "Epcoch 1, iter 650, loss 21.76125717163086\n",
      "Epcoch 1, iter 660, loss 32.387996673583984\n",
      "Epcoch 1, iter 670, loss 58.843631744384766\n",
      "Epcoch 1, iter 680, loss 28.95993995666504\n",
      "Epcoch 1, iter 690, loss 28.253215789794922\n",
      "Epcoch 1, iter 700, loss 63.45623016357422\n",
      "Epcoch 1, iter 710, loss 40.338165283203125\n",
      "Epcoch 1, iter 720, loss 53.98358917236328\n",
      "Epcoch 1, iter 730, loss 38.4739875793457\n",
      "Epcoch 1, iter 740, loss 27.061960220336914\n",
      "Epcoch 1, iter 750, loss 37.43650436401367\n",
      "Epcoch 1, iter 760, loss 28.029502868652344\n",
      "Epcoch 1, iter 770, loss 30.063814163208008\n",
      "Epcoch 1, iter 780, loss 28.19088363647461\n",
      "Epcoch 1, iter 790, loss 82.16251373291016\n",
      "Epcoch 1, iter 800, loss 171.23507690429688\n",
      "Epcoch 1, iter 810, loss 39.93557357788086\n",
      "Epcoch 1, iter 820, loss 14.307113647460938\n",
      "Epcoch 2, iter 0, loss 29.561372756958008\n",
      "Epcoch 2, iter 10, loss 30.603084564208984\n",
      "Epcoch 2, iter 20, loss 60.846439361572266\n",
      "Epcoch 2, iter 30, loss 19.65285873413086\n",
      "Epcoch 2, iter 40, loss 52.61616897583008\n",
      "Epcoch 2, iter 50, loss 30.092626571655273\n",
      "Epcoch 2, iter 60, loss 47.63213348388672\n",
      "Epcoch 2, iter 70, loss 20.435134887695312\n",
      "Epcoch 2, iter 80, loss 32.47785568237305\n",
      "Epcoch 2, iter 90, loss 41.737548828125\n",
      "Epcoch 2, iter 100, loss 38.782432556152344\n",
      "Epcoch 2, iter 110, loss 83.09860229492188\n",
      "Epcoch 2, iter 120, loss 26.33426284790039\n",
      "Epcoch 2, iter 130, loss 30.497638702392578\n",
      "Epcoch 2, iter 140, loss 18.967330932617188\n",
      "Epcoch 2, iter 150, loss 93.22178649902344\n",
      "Epcoch 2, iter 160, loss 126.49290466308594\n",
      "Epcoch 2, iter 170, loss 70.41304779052734\n",
      "Epcoch 2, iter 180, loss 55.955291748046875\n",
      "Epcoch 2, iter 190, loss 30.47283363342285\n",
      "Epcoch 2, iter 200, loss 60.938865661621094\n",
      "Epcoch 2, iter 210, loss 137.85614013671875\n",
      "Epcoch 2, iter 220, loss 13.611566543579102\n",
      "Epcoch 2, iter 230, loss 62.18959426879883\n",
      "Epcoch 2, iter 240, loss 55.675296783447266\n",
      "Epcoch 2, iter 250, loss 33.179443359375\n",
      "Epcoch 2, iter 260, loss 57.89531326293945\n",
      "Epcoch 2, iter 270, loss 45.83094787597656\n",
      "Epcoch 2, iter 280, loss 26.93419647216797\n",
      "Epcoch 2, iter 290, loss 43.84828567504883\n",
      "Epcoch 2, iter 300, loss 32.44981384277344\n",
      "Epcoch 2, iter 310, loss 27.27164077758789\n",
      "Epcoch 2, iter 320, loss 62.502872467041016\n",
      "Epcoch 2, iter 330, loss 118.84188079833984\n",
      "Epcoch 2, iter 340, loss 19.148523330688477\n",
      "Epcoch 2, iter 350, loss 27.035654067993164\n",
      "Epcoch 2, iter 360, loss 24.180896759033203\n",
      "Epcoch 2, iter 370, loss 10.498834609985352\n",
      "Epcoch 2, iter 380, loss 76.40721130371094\n",
      "Epcoch 2, iter 390, loss 106.26903533935547\n",
      "Epcoch 2, iter 400, loss 44.42603302001953\n",
      "Epcoch 2, iter 410, loss 43.65408706665039\n",
      "Epcoch 2, iter 420, loss 16.675472259521484\n",
      "Epcoch 2, iter 430, loss 26.547748565673828\n",
      "Epcoch 2, iter 440, loss 40.747947692871094\n",
      "Epcoch 2, iter 450, loss 37.8740234375\n",
      "Epcoch 2, iter 460, loss 25.63193702697754\n",
      "Epcoch 2, iter 470, loss 44.958072662353516\n",
      "Epcoch 2, iter 480, loss 26.03070640563965\n",
      "Epcoch 2, iter 490, loss 44.09884262084961\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for i, (img, kps) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        kps = kps.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epcoch {epoch}, iter {i}, loss {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
